######################## Libraries ###############################
import os
import pandas as pd
import numpy as np

######################## Import custom functions ###############################
from Scripts_snk.snakemake_functions import *

######################## Import values from the configuration file  ###############################
raw_vcf_file = config["raw_vcf_file"]
raw_data_path = config["raw_data_path"]
input_reference_genome = config["Reference_genome"]
working_directory = config["Working_directory"]

tmp_path = config["tmp_path"]

output_path = config["output_path"]

###################################### Global variables  ######################################
######################## Get the region names  ###############################
REGIONS = glob_wildcards(raw_vcf_file + "VCF_File_{region}.vcf.gz")

######################## Get the sample names  ###############################
SAMPLES = glob_wildcards(raw_data_path + config["samples"])
print(f"Samples:  {SAMPLES.sample}\n\n\n")

######################## Loop variables  ###############################
# These variables will be used to run several identical rules at different
# moments of the pipeline
STEPS=["1_Raw", "2_Mac", "3_Biallelic", "4_Missing", "5_QUAL", "6_DP", "7_SP", "8_Maf", "9_Hobs"]

######################## Other variables  ###############################
missing_rate = str(config["missing_rate"])
Hobs = str(config["Hobs"])
cutoff = str(config["cutoff"])


###################################### Memory allocation functions  ######################################
######################## Get the input file size  ###############################
def get_input_file_size(wildcards, input):
    return(input.size_mb)

######################## Double memory  ###############################
def double_mem(attempt):
    return(2**(attempt - 1))

######################## Filter on missing rates  ###############################
def get_mem_mb_plot_21(wildcards, input, attempt):
    input_file_size = get_input_file_size(wildcards, input)
    base_mem = input_file_size * 4
    return(min(base_mem * double_mem(attempt), 1500000))

######################## Rules  ###############################
######################## Rule all  ###############################
rule all:
    input:
        # Count_SNPs
        expand(output_path + "10_Stats/{step}/Position_count.csv", step=STEPS),
        # Concatenate_vcfs
        expand(output_path + "0{step}/VCF_File.vcf.gz", step=["2_Mac", "3_Biallelic", "4_Missing", "5_QUAL", "6_DP", "7_SP", "8_Maf"]),
        # Stats
        expand(output_path + "10_Stats/{step}/vcfstats.QUAL.txt", step=STEPS),
        expand(output_path + "10_Stats/{step}/vcfstats.SP.txt", step=STEPS),
        expand(output_path + "10_Stats/{step}/vcfstats.AF.txt", step=STEPS),
        expand(output_path + "10_Stats/{step}/vcfstats.DP.txt", step=STEPS),
        expand(output_path + "10_Stats/{step}/Quality_distribution.png", step=STEPS),


######################## Filter only interested samples  ###############################
rule N01_LOKn_LAMn:
    input:
        raw_vcf_file + "VCF_File_{region}.vcf.gz"
    output:
        temp(tmp_path + "01_MAC/VCF_File_{region}.vcf.gz")
    params:
        indivs = expand("--indv {sample}", sample=SAMPLES.sample),
        tmp_path = tmp_path
    message:
        "Filtering Max Allele Count for {wildcards.region}"
    conda:
        working_directory + "Configuration_files/envs/Environment.yaml"
    shell:
        """
            vcftools --gzvcf {input:q} --stdout --mac 1 {params.indivs} --temp {params.tmp_path:q} --recode | gzip -c > {output:q}
        """


######################## Remove Indels and multiallelic sites  ###############################
rule N02_Remove_Indels:
    input:
        rules.N01_LOKn_LAMn.output
    output:
        temp(tmp_path + "02_Biall/VCF_File_{region}.vcf.gz")
    threads: 10
    message:
        "Removing Indels and multiallelic sites for {wildcards.region}"
    conda:
        working_directory + "Configuration_files/envs/Environment.yaml"
    shell:
        """
            bcftools filter -Ou --threads {threads} -g 5:indel,other {input:q} | bcftools view -Oz --threads {threads} -M 2 -m 2 -v snps > {output:q}
        """


######################## Remove sites with missing data  ###############################
rule N03_Filter_missing_rate:
    input:
        rules.N02_Remove_Indels.output
    output:
        temp(tmp_path + "03_Missing/VCF_File_{region}.vcf.gz")
    params:
        tmp_path = tmp_path,
        missing_rate = missing_rate
    conda:
        working_directory + "Configuration_files/envs/Environment.yaml"
    shell:
        """
            vcftools --gzvcf {input:q} --stdout --max-missing {params.missing_rate:q} --temp {tmp_path:q} --recode | gzip -c > {output:q}
        """


######################## Filtration on Phred scaled variant quality score (QUAL)  ###############################
rule N04_QUAL_filtration:
    input:
        rules.N03_Filter_missing_rate.output
    output:
        temp(tmp_path + "04_QUAL_filt/VCF_File_{region}.vcf.gz")
    conda:
        working_directory + "Configuration_files/envs/Environment.yaml"
    shell:
        """
            bcftools filter -Oz -e "QUAL<30" {input:q} > {output:q}
        """


######################## Filtration on mean depth read (DP)  ###############################
rule N05_DP_filtration:
    input:
        rules.N04_QUAL_filtration.output
    output:
        temp(tmp_path + "05_DP_filt/VCF_File_{region}.vcf.gz")
    params:
        tmp_path = tmp_path
    conda:
        working_directory + "Configuration_files/envs/Environment.yaml"
    shell:
        """
            vcftools --gzvcf {input:q} --stdout --max-meanDP 13 --min-meanDP 5 --temp {params.tmp_path:q} --recode | gzip -c > {output:q}
        """


######################## Filtration on Phred proba of strand bias (SP)  ###############################
rule N06_SP_filtration_prep:
    input:
        tmp_path + "10_Stats/6_DP/phred_qual_{region}.txt"
    output:
        temp(tmp_path + "DP_List_SP_Filt/List_SP_{region}.tsv")
    params:
        cutoff = cutoff,
        working_directory = working_directory
    conda:
        working_directory + "Configuration_files/envs/Environment.yaml"
    shell:
        """
            Rscript {params.working_directory:q}Scripts_snk/Table_maker_SP.r --input {input:q} --output {output:q} --cutoff {params.cutoff:q}
        """


rule N06_SP_filtration:
    input:
        vcf_file = rules.N05_DP_filtration.output,
        stats = rules.N06_SP_filtration_prep.output
    output:
        temp(tmp_path + "06_SP_filt/VCF_File_{region}.vcf.gz")
    params:
        tmp_path = tmp_path
    conda:
        working_directory + "Configuration_files/envs/Environment.yaml"
    shell:
        """
            vcftools --gzvcf {input.vcf_file:q} --positions {input.stats:q} --recode --stdout --temp {params.tmp_path:q} | gzip -c > {output:q}
        """


######################## MAF and thin filtration  ###############################
rule N07_maf_thin_filtration:
    input:
        rules.N06_SP_filtration.output
    output:
        temp(tmp_path + "07_Full_vcf/VCF_File_{region}.vcf.gz")
    params:
        tmp_path = tmp_path
    conda:
        working_directory + "Configuration_files/envs/Environment.yaml"
    shell:
        """
            vcftools --gzvcf {input:q} --stdout --recode --maf 0.05 --thin 1000 --temp {params.tmp_path:q} | gzip -c > {output:q}
        """


######################## MAF and thin filtration  ###############################
rule N08_Hobs_filtration:
    input:
        rules.N07_maf_thin_filtration.output
    output:
        temp(tmp_path + "08_Hobs/VCF_File_{region}.vcf.gz")
    params:
        tmp_path = tmp_path,
        working_directory = working_directory,
        Hobs = Hobs
    conda:
        working_directory + "Configuration_files/envs/Environment.yaml"
    shell:
        """
            Rscript {params.working_directory:q}Scripts_snk/Filter_Hobs.r --input {input:q} --output {output:q} --Hobs {params.Hobs:q} --tmp {params.tmp_path:q}
        """


######################## SNP Count  ###############################
def make_rule_count_SNPs(step, raw_vcf_file, tmp_path, output_path):
    rule:
        name: f"N08.{step.split('_')[0]}_Count_SNPs_on_{this_step(step)}_data"
        input:
            find_step_input(step, raw_vcf_file, tmp_path, output_path) + "VCF_File_{region}.vcf.gz"
        output:
            temp(tmp_path + f"10_Stats/{step}/Position_count_{{region}}.csv")
        shell:
            """
                NSNPs=$(echo "$(zcat {input:q} | grep -v '#' | wc -l) + 1" | bc)
                echo "{wildcards.region};$(echo "$NSNPs -1 " | bc)" >> {output:q}
            """

    rule:
        name: f"N09.{step.split('_')[0]}_Concat_SNP_count_on_{this_step(step)}_data"
        input:
            expand(tmp_path + f"10_Stats/{step}/Position_count_{{region}}.csv", region=REGIONS.region)
        output:
            output_path + f"10_Stats/{step}/Position_count.csv"
        shell:
            """
                cat {input:q} >> {output:q}
            """

######################## Concat vcf files  ###############################
def concat_vcf(step, raw_vcf_file, tmp_path, output_path):
    rule:
        name: f"N10.{step.split('_')[0]}_Concat_VCF_file_after_{this_step(step)}"
        input:
            expand(find_step_input(step, raw_vcf_file, tmp_path, output_path) + "VCF_File_{region}.vcf.gz", region=REGIONS.region)
        output:
            temp_out = temp(tmp_path + f"{step}/VCF_File.vcf"),
            real = output_path + f"0{step}/VCF_File.vcf.gz"
        params:
            out_dir = tmp_path + f"{step}/"
        shell:
            """
                mkdir -p {params.out_dir:q}
                zcat {input[0]:q} | grep "#" > {output.temp_out:q}
                for file in {input:q}; do
                    zcat "$file" | grep -v "#" >> {output.temp_out:q}
                done
                gzip -c {output.temp_out:q} > {output:q}
            """

######################## Do Stats  ###############################
def stats_vcf(step, raw_vcf_file, tmp_path, output_path):
    rule:
        name: f"N11.{step.split('_')[0]}_Stats_on_{this_step(step)}_data"
        input:
            find_step_input(step, raw_vcf_file, tmp_path, output_path) + "VCF_File_{region}.vcf.gz"
        output:
            site_qual = temp(tmp_path + f"10_Stats/{step}/site_qual_{{region}}.txt"),
            phred = temp(tmp_path + f"10_Stats/{step}/phred_qual_{{region}}.txt"),
            allel_freq = temp(tmp_path + f"10_Stats/{step}/allel_freq_{{region}}.txt"),
            depth = temp(tmp_path + f"10_Stats/{step}/tot_depth_{{region}}.ldepth.mean"),
            missing = temp(tmp_path + f"10_Stats/{step}/{{region}}.lmiss")
        params:
            OUTDIR_Stats = tmp_path + f"10_Stats/{step}/tot_depth_{{region}}",
            prefix_missing = tmp_path + f"10_Stats/{step}/{{region}}",
            tmp_path = tmp_path
        conda:
            working_directory + "Configuration_files/envs/Environment.yaml"
        shell:
            r"""
                # Call quality per site
                bcftools query -f "%CHROM\t%POS\t%QUAL\n" {input:q} > {output.site_qual:q}

                # Strand-bias P-value (Phread score)
                bcftools query -f "%CHROM\t%POS\t[%SP\t]\n" {input:q} | awk 'BEGIN{{OFS="\t"}}{{sum=0; for (i=3; i<=NF; i++) sum+=$i; sum/=NF; print $1,$2,sum}}' > {output.phred:q}

                # Depth per sample
                bcftools +fill-tags {input:q} -- -t AF | bcftools query -f "%CHROM\t%POS\t%AF\n" > {output.allel_freq:q}

                # Mean depth
                vcftools --gzvcf {input:q} --site-mean-depth --temp {params.tmp_path:q} --out {params.OUTDIR_Stats:q}

                # Missing data
                vcftools --gzvcf {input:q} --out {params.prefix_missing:q} --missing-site --temp {params.tmp_path:q}

            """

    rule:
        name: f"N12.{step.split('_')[0]}_Concat_stats_on_{this_step(step)}"
        input:
            site_qual = expand(tmp_path + f"10_Stats/{step}/site_qual_{{region}}.txt", region=REGIONS.region),
            phred = expand(tmp_path + f"10_Stats/{step}/phred_qual_{{region}}.txt", region=REGIONS.region),
            allel_freq = expand(tmp_path + f"10_Stats/{step}/allel_freq_{{region}}.txt", region=REGIONS.region),
            depth = expand(tmp_path + f"10_Stats/{step}/tot_depth_{{region}}.ldepth.mean", region=REGIONS.region),
            missing = expand(tmp_path + f"10_Stats/{step}/{{region}}.lmiss", region=REGIONS.region)
        output:
            site_qual = output_path + f"10_Stats/{step}/vcfstats.QUAL.txt", 
            phred = output_path + f"10_Stats/{step}/vcfstats.SP.txt", 
            allel_freq = output_path + f"10_Stats/{step}/vcfstats.AF.txt",
            depth = output_path + f"10_Stats/{step}/vcfstats.DP.txt",
            missing = output_path + f"10_Stats/{step}/vcfstats.lmiss"
        params:
            indir = tmp_path + f"10_Stats/{step}/" 
        shell:
            """
                cat {params.indir:q}site_qual_*.txt > {output.site_qual:q}
                cat {params.indir:q}phred_qual*.txt > {output.phred:q}
                cat {params.indir:q}allel_freq_*.txt > {output.allel_freq:q}
                cat {params.indir:q}*.ldepth.mean | sort -n -k1,1 -k2,2 | uniq > {output.depth:q}
                cat {params.indir:q}*.lmiss | sort -n -k1,1 -k2,2 | uniq > {output.missing:q}
            """
    
    if step != "Raw":
        rule:
            name: f"N13.{step.split('_')[0]}_Plot_graph_on_{this_step(step)}"
        input:
            site_qual = output_path + f"10_Stats/{step}/vcfstats.QUAL.txt", 
            phred = output_path + f"10_Stats/{step}/vcfstats.SP.txt", 
            allel_freq = output_path + f"10_Stats/{step}/vcfstats.AF.txt",
            depth = output_path + f"10_Stats/{step}/vcfstats.DP.txt",
            missing = output_path + f"10_Stats/{step}/vcfstats.lmiss"
        output:
            output_path + f"10_Stats/{step}/Quality_distribution.png"
        resources:
            mem_mb = get_mem_mb_plot_21
        conda:
            working_directory + "Configuration_files/envs/Environment.yaml"
        params:
            input_path = output_path + f"10_Stats/{step}/",
            out_name = output_path + f"10_Stats/{step}/Quality_distribution",
            working_directory = working_directory
        shell:
            """
                Rscript {params.working_directory:q}Scripts_snk/Graph_quality.r --input {params.input_path:q} --output {params.out_name:q}
            """

######################## Stats (nb_positins, quality, depth, concatenation) for each step  ###############################
for step in STEPS:
    make_rule_count_SNPs(step, raw_vcf_file, tmp_path, output_path)
    stats_vcf(step, raw_vcf_file, tmp_path, output_path)
    if step == "Raw":
        continue
    else:
        concat_vcf(step, raw_vcf_file, tmp_path, output_path)
