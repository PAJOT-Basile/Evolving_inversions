# ------------------------------------------------------------------
#                   Basile Pajot, 2024
#                   baspajot@gmail.com
#     Script to filter a VCF file from selected samples
# ------------------------------------------------------------------
######################## Libraries ###############################
import os, sys
import pandas as pd
import numpy as np
from math import log

######################## Import custom functions ###############################
from Scripts_snk.snakemake_functions import *

######################## Import values from the configuration file  ###############################
# Inputs
raw_data_path = config["raw_data_path"]
pop_map_path = config["pop_maps"]
working_directory = config["Working_directory"]

# Conda environment
conda_environment = working_directory + "Configuration_files/envs/"

# Temporary paths
tmp_path = config["tmp_path"]

# Output path
output_path = config["output_path"]
base_output = "02_Filter_VCF/"

# Check if the input file exists
if not os.path.isdir(pop_map_path):
    sys.exit(
        """
        No valid Pop_map directory is given. Please create a Pop_map directory containing one text file per population you want to
        add to the analysis. The text file should contain the names of the samples you want to use, without the file extensions.
        Several populations may be given in this Pop_map directory.
        """
    )
###################################### Global variables  ######################################
######################## Get the region names  ###############################
REGIONS = glob_wildcards(raw_data_path + "VCF_File_{region}.vcf.gz").region

######################## Get the names of the popmaps  ###############################
POP_MAP = glob_wildcards(pop_map_path + "{populations}.txt")

######################## Get the sample names  ###############################
SAMPLES = {}
for population in POP_MAP.populations:
    with open(pop_map_path + population + ".txt", "r") as f:
        SAMPLES[population] = f.read().splitlines()

######################## Loop variables  ###############################
# These variables will be used to run several identical rules at different
# moments of the pipeline
STEPS=["1_Indivs", "2_Mac", "3_Biallelic", "4_Missing", "5_QUAL", "6_DP", "7_SP", "8_Hobs", "9_Maf_thin"]

######################## Other variables  ###############################
missing_rate = str(config["missing_rate"])
mac = str(config["mac"])
maf = str(config["maf"])
thin = str(config["thin"])
Hobs = str(config["Hobs"])
cutoff = str(config["cutoff"])


###################################### Memory allocation functions  ######################################
######################## Get the input file size  ###############################
def get_input_file_size(wildcards, input):
    return(input.size_mb)

######################## Double memory  ###############################
def double_mem(attempt):
    return(2**(attempt - 1))

######################## MAC  ###############################
def get_mem_mb_mac(wildcards, input, attempt):
    start, end = str(wildcards.region).split(":")[1].split("-")
    region_length = int(end) - int(start) + 1
    input_file_size = get_input_file_size(wildcards, input)
    base_mem = 3e-4 * input_file_size + 2.5e-7 * region_length + 305
    return base_mem * double_mem(attempt)


######################## Remove Indels  ###############################
def get_mem_mb_remove_indels(wildcards, attempt):
    start, end = str(wildcards.region).split(":")[1].split("-")
    region_length = int(end) - int(start) + 1
    base_mem = 1300 * log(region_length) - 12000
    return base_mem * double_mem(attempt)


######################## Filter on missing rates  ###############################
def get_mem_mb_missing(wildcards, input, attempt):
    start, end = str(wildcards.region).split(":")[1].split("-")
    region_length = int(end) - int(start) + 1
    input_file_size = get_input_file_size(wildcards, input)
    base_mem = 0.03 * input_file_size + 40 * log(region_length) - 1
    return base_mem * double_mem(attempt)


######################## Plot output  ###############################
def get_mem_mb_plot(wildcards, input, attempt):
    input_file_size = get_input_file_size(wildcards, input)
    base_mem = input_file_size * 4
    return min(base_mem * double_mem(attempt), 1500000)
    
######################## Rules  ###############################
######################## Rule all  ###############################
rule all:
    input:
        # Concatenate_vcfs
        expand(output_path + "{population}/" + base_output + "0{step}/VCF_File.vcf.gz", population = POP_MAP.populations, step=["1_Indivs", "7_SP", "8_Hobs", "9_Maf_thin"]),
        # Stats
        expand(output_path + "{population}/" + base_output + "10_Stats/{step}/vcfstats.QUAL.txt", population = POP_MAP.populations, step=STEPS),
        expand(output_path + "{population}/" + base_output + "10_Stats/{step}/vcfstats.SP.txt", population = POP_MAP.populations, step=STEPS),
        expand(output_path + "{population}/" + base_output + "10_Stats/{step}/vcfstats.AF.txt", population = POP_MAP.populations, step=STEPS),
        expand(output_path + "{population}/" + base_output + "10_Stats/{step}/vcfstats.DP.txt", population = POP_MAP.populations, step=STEPS),
        expand(output_path + "{population}/" + base_output + "10_Stats/{step}/Quality_distribution.png", population = POP_MAP.populations, step=STEPS),
        # Count_SNPs
        expand(output_path + "{population}/" + base_output + "10_Stats/{step}/Position_count.csv", population = POP_MAP.populations, step=STEPS),


######################## Filter only interested samples  ###############################
rule N01_Select_indivs:
    input:
        raw_data_path + "VCF_File_{region}.vcf.gz"
    output:
        temp(tmp_path + "{population}/01_Indivs/VCF_File_{region}.vcf.gz")
    params:
        indivs = lambda wildcards: expand("--indv {sample}", sample=SAMPLES[wildcards.population]),
        tmp_path = tmp_path
    message:
        "Selecting right individuals for {wildcards.region} and {wildcards.population}"
    log:
        "logs/N01_Select_indivs/{population}_{region}.log"
    conda:
        conda_environment + "N01_Select_indivs.yaml"
    shell:
        """
            vcftools --gzvcf {input:q} --stdout {params.indivs} --temp {params.tmp_path:q} --recode 2> {log} | gzip -c > {output:q} 2> {log}
        """


######################## Filter on MAC  ###############################
rule N02_MAC_filtration:
    input:
        rules.N01_Select_indivs.output
    output:
        temp(tmp_path + "{population}/02_MAC/VCF_File_{region}.vcf.gz")
    params:
        tmp_path = tmp_path,
        mac = mac
    conda:
        conda_environment + "N02_MAC_filtration.yaml"
    resources:
        mem_mb = get_mem_mb_mac
    log:
        "logs/N02_MAC_filtration/{population}_{region}.log"
    shell:
        """
            vcftools --gzvcf {input:q} --stdout --mac {params.mac:q} --temp {params.tmp_path:q} --recode 2> {log} | gzip -c > {output:q} 2> {log}
        """

######################## Remove Indels and multiallelic sites  ###############################
rule N03_Remove_Indels:
    input:
        rules.N02_MAC_filtration.output
    output:
        temp(tmp_path + "{population}/03_Indels_multiall/VCF_File_{region}.vcf.gz")
    params:
        tmp_path = tmp_path
    threads: 10
    resources:
        mem_mb = get_mem_mb_remove_indels
    message:
        "Removing Indels and multiallelic sites for {wildcards.region} and {wildcards.population}"
    log:
        "logs/N03_Remove_Indels/{population}_{region}.log"
    conda:
        conda_environment + "N03_Remove_Indels.yaml"
    shell:
        """
            bcftools sort -Ou -T {params.tmp_path:q} {input:q} | bcftools filter -Ou --threads {threads} -g 5:indel,other | bcftools view -Oz --threads {threads} -M 2 -m 2 -v snps > {output:q} 2> {log}
        """


######################## Remove sites with missing data  ###############################
rule N04_Filter_missing_rate:
    input:
        rules.N03_Remove_Indels.output
    output:
        temp(tmp_path + "{population}/04_Missing/VCF_File_{region}.vcf.gz")
    params:
        tmp_path = tmp_path,
        missing_rate = missing_rate
    conda:
        conda_environment + "N04_Filter_missing_rate.yaml"
    resources:
        mem_mb = get_mem_mb_missing
    log:
        "logs/N04_Filter_missing_rate/{population}_{region}.log"
    shell:
        """
            vcftools --gzvcf {input:q} --stdout --max-missing {params.missing_rate:q} --temp {tmp_path:q} --recode 2> {log} | gzip -c > {output:q} 2> {log}
        """


######################## Filtration on Phred scaled variant quality score (QUAL)  ###############################
rule N05_QUAL_filtration:
    input:
        rules.N04_Filter_missing_rate.output
    output:
        temp(tmp_path + "{population}/05_QUAL/VCF_File_{region}.vcf.gz")
    conda:
        conda_environment + "N05_QUAL_filtration.yaml"
    params:
        tmp_path = tmp_path
    log:
        "logs/N05_QUAL_filtration/{population}_{region}.log"
    shell:
        """
            bcftools sort -Ou -T {params.tmp_path:q} {input:q} | bcftools filter -Oz -e "QUAL<30" > {output:q} 2> {log}
        """


######################## Filtration on mean depth read (DP)  ###############################
rule N06_DP_filtration:
    input:
        rules.N05_QUAL_filtration.output
    output:
        temp(tmp_path + "{population}/06_DP/VCF_File_{region}.vcf.gz")
    params:
        tmp_path = tmp_path
    conda:
        conda_environment + "N06_DP_filtration.yaml"
    log:
        "logs/N06_DP_filtration/{population}_{region}.log"
    shell:
        """
            vcftools --gzvcf {input:q} --stdout --max-meanDP 13 --min-meanDP 5 --temp {params.tmp_path:q} --recode 2> {log} | gzip -c > {output:q} 2> {log}
        """


######################## Filtration on Phred proba of strand bias (SP)  ###############################
rule N07_SP_filtration_prep:
    input:
        tmp_path + "{population}/10_Stats/6_DP/phred_qual_{region}.txt"
    output:
        temp(tmp_path + "{population}/DP_List_SP_Filt/List_SP_{region}.tsv")
    params:
        cutoff = cutoff,
        working_directory = working_directory
    conda:
        conda_environment + "N07_SP_filtration_prep.yaml"
    log:
        "logs/N07_SP_filtration_prep/{population}_{region}.log"
    shell:
        """
            Rscript {params.working_directory:q}Scripts_snk/Table_maker_SP.r --input {input:q} --output {output:q} --cutoff {params.cutoff:q} 2>&1
        """


rule N07_SP_filtration:
    input:
        vcf_file = rules.N06_DP_filtration.output,
        stats = rules.N07_SP_filtration_prep.output
    output:
        temp(tmp_path + "{population}/07_SP/VCF_File_{region}.vcf.gz")
    params:
        tmp_path = tmp_path
    conda:
        conda_environment + "N07_SP_filtration.yaml"
    log:
        "logs/N07_SP_filtration/{population}_{region}.log"
    shell:
        """
            vcftools --gzvcf {input.vcf_file:q} --positions {input.stats:q} --recode --stdout --temp {params.tmp_path:q} 2> {log} | gzip -c > {output:q} 2> {log}
        """


########################  Hobs  ###############################
rule N08_Hobs_filtration:
    input:
        rules.N07_SP_filtration.output
    output:
        vcf = temp(tmp_path + "{population}/08_Hobs/VCF_File_{region}.vcf.gz"),
        tsv = temp(tmp_path + "{population}/08_Hobs/Filter_vcf_Hobs_{region}.tsv")
    params:
        tmp_path = tmp_path,
        working_directory = working_directory,
        Hobs = Hobs
    conda:
        conda_environment + "N08_Hobs_filtration.yaml"
    log:    
        "logs/N08_Hobs_filtration/{population}_{region}.log"
    resources:
        mem_mb = 32000
    shell:
        """
            Rscript {params.working_directory:q}Scripts_snk/Filter_Hobs.r --input {input:q} --output {output.vcf:q} --Hobs {params.Hobs:q} --tmp {params.tmp_path:q} 2>&1
        """

######################## MAF and thin filtration  ###############################
rule N09_maf_thin_filtration:
    input:
        rules.N08_Hobs_filtration.output.vcf
    output:
        temp(tmp_path + "{population}/09_Maf_thin/VCF_File_{region}.vcf.gz")
    params:
        tmp_path = tmp_path,
        maf = maf,
        thin = thin
    conda:
        conda_environment + "N09_maf_thin_filtration.yaml"
    log:
        "logs/N09_maf_thin_filtration/{population}_{region}.log"
    shell:
        """
            vcftools --gzvcf {input:q} --stdout --recode --maf {params.maf:q} --thin {params.thin:q} --temp {params.tmp_path:q} | bgzip -c > {output:q} 2> {log:q}
        """


######################## SNP Count  ###############################
def make_rule_count_SNPs(step, tmp_path, output_path):
    rule:
        name: f"N10.{step.split('_')[0]}_Count_SNPs_on_{this_step(step)}_data"
        input:
            lambda wildcards: find_step_input(step, wildcards.population, tmp_path) + "VCF_File_{region}.vcf.gz"
        output:
            temp(tmp_path + "{population}/10_Stats/" + step + "/Position_count_{region}.csv")
        log:
            "logs/N10_Count/" + step + "/{population}_{region}.log"
        shell:
            """
                NSNPs=$(echo "$(zcat {input:q} | grep -v '#' | wc -l) + 1" | bc)
                echo "{wildcards.region};$(echo "$NSNPs -1 " | bc)" >> {output:q} 2>&1
            """

    rule:
        name: f"N11.{step.split('_')[0]}_Concat_SNP_count_on_{this_step(step)}_data"
        input:
            expand(tmp_path + "{population}/10_Stats/" + step + "/Position_count_{region}.csv", region=REGIONS, allow_missing = True)
        output:
            output_path + "{population}/" + base_output + "10_Stats/" + step + "/Position_count.csv"
        log:
            "logs/N11_Concat_SNP/" + step + "/{population}.log"
        shell:
            """
                cat {input:q} >> {output:q} 2>&1
            """

######################## Concat vcf files  ###############################
def concat_vcf(step, tmp_path, output_path):
    rule:
        name: f"N12.{step.split('_')[0]}_Sort_vcf_file_on_{this_step(step)}"
        input:
            find_step_input(step, "{population}", tmp_path) + "VCF_File_{region}.vcf.gz"
        output:
            vcf = temp(tmp_path + "{population}/" + step + "/VCF_File_sorted_{region}.vcf.gz"),
        params:
            temp_out_dir = tmp_path
        conda:
            conda_environment + "N12_Sort_vcf_file.yaml"
        log:
            "logs/N12_Sort/" + step + "/{population}_{region}.log"
        shell:
            """
                bcftools sort {input:q} -Oz -T {params.temp_out_dir:q} -o {output.vcf:q} 2> {log}
            """

    rule:
        name: f"N13.{step.split('_')[0]}_Index_vcf_file_on_{this_step(step)}"
        input:
            tmp_path + "{population}/" + step + "/VCF_File_sorted_{region}.vcf.gz"
        output:
            index = temp(tmp_path + "{population}/" + step + "/VCF_File_sorted_{region}.vcf.gz.tbi")
        params:
            temp_out_dir = tmp_path
        conda:
            conda_environment + "N13_Index_vcf_file.yaml"
        log:
            "logs/N13_Index/" + step + "/{population}_{region}.log"
        shell:
            """
                bcftools index -o {output.index:q} {input:q} 2> {log}
            """
    rule:
        name: f"N14.{step.split('_')[0]}_Concat_vcf_after_filtering_on_{this_step(step)}"
        input:
            vcf = expand(tmp_path + "{population}" + "/" + step + "/VCF_File_sorted_{region}.vcf.gz", region=REGIONS, allow_missing = True),
            index = expand(tmp_path + "{population}/" + step + "/VCF_File_sorted_{region}.vcf.gz.tbi", region=REGIONS, allow_missing = True)
        output:
            output_path + "{population}/" + base_output + "0" + step + "/VCF_File.vcf.gz"
        params:
            tmp_path = tmp_path
        resources:
            slurm_partition = "long",
            runtime = "345600", # 4 days
            mem = lambda wildcards, attempt: 8000 * double_mem(attempt)
        conda:
            conda_environment + "N14_Concat_vcf_after_filtering.yaml"
        log:    
            "logs/N14_Concat_VCF/" + step + "/{population}.log"
        shell:
            """
                bcftools concat {input.vcf:q} -D -a -Ou | bcftools sort -T {params.tmp_path:q} -Oz -o {output:q} 2>{log:q}
            """
    

######################## Do Stats  ###############################
def stats_vcf(step, tmp_path, output_path):
    rule:
        name: f"N15.{step.split('_')[0]}_Stats_on_{this_step(step)}_data"
        input:
            find_step_input(step, "{population}", tmp_path) + "VCF_File_{region}.vcf.gz"
        output:
            site_qual = temp(tmp_path + "{population}/10_Stats/" + step + "/site_qual_{region}.txt"),
            phred = temp(tmp_path + "{population}/10_Stats/" + step + "/phred_qual_{region}.txt"),
            allel_freq = temp(tmp_path + "{population}/10_Stats/" + step + "/allel_freq_{region}.txt"),
            depth = temp(tmp_path + "{population}/10_Stats/" + step + "/tot_depth_{region}.ldepth.mean"),
            missing = temp(tmp_path + "{population}/10_Stats/" + step + "/{region}.lmiss")
        params:
            OUTDIR_Stats = tmp_path + "{population}/10_Stats/" + step + "/tot_depth_{region}",
            prefix_missing = tmp_path + "{population}/10_Stats/" + step + "/{region}",
            tmp_path = tmp_path
        conda:
            conda_environment + "N15_Stats_data.yaml"
        log:
            "logs/N15_Stats/" + step + "/{population}_{region}.log"
        shell:
            r"""
                # Call quality per site
                bcftools query -f "%CHROM\t%POS\t%QUAL\n" {input:q} > {output.site_qual:q} 2> {log}

                # Strand-bias P-value (Phread score)
                bcftools query -f "%CHROM\t%POS\t[%SP\t]\n" {input:q} | awk 'BEGIN{{OFS="\t"}}{{sum=0; for (i=3; i<=NF; i++) sum+=$i; sum/=NF; print $1,$2,sum}}' > {output.phred:q} 2> {log}

                # Depth per sample
                bcftools +fill-tags {input:q} -- -t AF | bcftools query -f "%CHROM\t%POS\t%AF\n" > {output.allel_freq:q} 2> {log}

                # Mean depth
                vcftools --gzvcf {input:q} --site-mean-depth --temp {params.tmp_path:q} --out {params.OUTDIR_Stats:q} 2> {log}

                # Missing data
                vcftools --gzvcf {input:q} --out {params.prefix_missing:q} --missing-site --temp {params.tmp_path:q} 2> {log}

            """

    rule:
        name: f"N16.{step.split('_')[0]}_Concat_stats_on_{this_step(step)}"
        input:
            site_qual = expand(tmp_path + "{population}/10_Stats/" + step + "/site_qual_{region}.txt", region=REGIONS, allow_missing = True),
            phred = expand(tmp_path + "{population}/10_Stats/" + step + "/phred_qual_{region}.txt", region=REGIONS, allow_missing = True),
            allel_freq = expand(tmp_path + "{population}/10_Stats/" + step + "/allel_freq_{region}.txt", region=REGIONS, allow_missing = True),
            depth = expand(tmp_path + "{population}/10_Stats/" + step + "/tot_depth_{region}.ldepth.mean", region=REGIONS, allow_missing = True),
            missing = expand(tmp_path + "{population}/10_Stats/" + step + "/{region}.lmiss", region=REGIONS, allow_missing = True)
        output:
            site_qual = output_path + "{population}/" + base_output + "10_Stats/" + step + "/vcfstats.QUAL.txt", 
            phred = output_path + "{population}/" + base_output + "10_Stats/" + step + "/vcfstats.SP.txt", 
            allel_freq = output_path + "{population}/" + base_output + "10_Stats/" + step + "/vcfstats.AF.txt",
            depth = output_path + "{population}/" + base_output + "10_Stats/" + step + "/vcfstats.DP.txt",
            missing = output_path + "{population}/" + base_output + "10_Stats/" + step + "/vcfstats.lmiss"
        resources:
            mem_mb = lambda wildcards, attempt: 8000 * double_mem(attempt)
        params:
            indir = tmp_path + "{population}/10_Stats/" + step + "/" 
        log:
            "logs/N16_Concat_Stats/" + step + "/{population}.log"
        shell:
            """
                cat {params.indir:q}site_qual_*.txt > {output.site_qual:q} 2> {log}
                cat {params.indir:q}phred_qual*.txt > {output.phred:q} 2> {log}
                cat {params.indir:q}allel_freq_*.txt > {output.allel_freq:q} 2> {log}
                cat {params.indir:q}*.ldepth.mean | sort -n -k1,1 -k2,2 | uniq > {output.depth:q} 2> {log}
                cat {params.indir:q}*.lmiss | sort -n -k1,1 -k2,2 | uniq > {output.missing:q} 2> {log}
            """
    
    rule:
        name: f"N17.{step.split('_')[0]}_Plot_graph_on_{this_step(step)}"
        input:
            site_qual = output_path + "{population}/" + base_output + "10_Stats/" + step + "/vcfstats.QUAL.txt", 
            phred = output_path + "{population}/" + base_output + "10_Stats/" + step + "/vcfstats.SP.txt", 
            allel_freq = output_path + "{population}/" + base_output + "10_Stats/" + step + "/vcfstats.AF.txt",
            depth = output_path + "{population}/" + base_output + "10_Stats/" + step + "/vcfstats.DP.txt",
            missing = output_path + "{population}/" + base_output + "10_Stats/" + step + "/vcfstats.lmiss"
        output:
            output_path + "{population}/" + base_output + "10_Stats/" + step + "/Quality_distribution.png"
        resources:
            mem_mb = get_mem_mb_plot
        conda:
            conda_environment + "N17_Plot_graph.yaml"
        params:
            input_path = output_path + "{population}/" + base_output + "10_Stats/" + step + "/",
            out_dir_path = output_path + "{population}/" + base_output + "10_Stats/" + step + "/Quality_distribution",
            working_directory = working_directory
        log:
            "logs/N17_Plot/" + step + "/{population}.log"
        shell:
            """
                Rscript {params.working_directory:q}Scripts_snk/Graph_quality.r --input {params.input_path:q} --output {params.out_dir_path:q} 2> {log}
            """

######################## Stats (nb_positins, quality, depth, concatenation) for each step  ###############################
for step in STEPS:
    make_rule_count_SNPs(step, tmp_path, output_path)
    stats_vcf(step, tmp_path, output_path)
    if step in ["1_Indivs", "7_SP", "8_Hobs", "9_Maf_thin"]:
        concat_vcf(step, tmp_path, output_path)
